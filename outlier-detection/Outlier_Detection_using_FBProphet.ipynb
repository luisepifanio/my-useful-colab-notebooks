{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Outlier Detection using FBProphet.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luisepifanio/my-useful-colab-notebooks/blob/features%2Foutlier-detection/outlier-detection/Outlier_Detection_using_FBProphet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyU9U3gch1S7"
      },
      "source": [
        "# 1. Choose your execution environment\n",
        "- If you want to use GPUs, please setup your environment before start\n",
        "- First, you'll need to enable GPUs for the notebook:\n",
        "\n",
        "1.    Navigate to Edit → Notebook Settings\n",
        "2.    Select GPU from the Hardware Accelerator drop-down\n",
        "\n",
        "<figure>\n",
        "<center>\n",
        "<img src='https://www.tutorialspoint.com/google_colab/images/enabling_gpu.jpg' />\n",
        "<figcaption>Image Caption</figcaption></center>\n",
        "</figure>\n",
        "\n",
        "Next, we'll confirm that we can connect to the GPU with tensorflow:\n",
        "\n",
        " \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1JW9lamC0Zt"
      },
      "source": [
        "# import tensorflow as tf\n",
        "# tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wjuhy5-pVtgL"
      },
      "source": [
        "# 2. Recreate folder  estructure about\n",
        "Next step is about regenerate project structures to work:\n",
        "- modules or relevant imports\n",
        "- dataset to work\n",
        "\n",
        "So, let's start downloading code and config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hIUzomxZrcJ"
      },
      "source": [
        "from typing import List\n",
        "\n",
        "\n",
        "\n",
        "base_url:str=\"https://raw.githubusercontent.com/luisepifanio/my-useful-colab-notebooks\"\n",
        "git_branch:str = \"features/outlier-detection\"\n",
        "folder:str=\"outlier-detection\"\n",
        "\n",
        "#General folders\n",
        "!mkdir -p \"./modules\"\n",
        "!mkdir -p \"./datasets\"\n",
        "\n",
        "# Files on root\n",
        "environment_file:str = f\"{base_url}/{git_branch}/{folder}/environment.yml\"\n",
        "files_on_root:List[str] = [environment_file]\n",
        "\n",
        "for file in files_on_root:\n",
        "  !wget --continue $file -P \".\" -nc\n",
        "\n",
        "# code files on modules\n",
        "files_on_modules:List[str] = [\n",
        "  f\"{base_url}/{git_branch}/{folder}/modules/outlier_utils.py\"\n",
        "]\n",
        "\n",
        "for file in files_on_modules:\n",
        "  !wget --continue $file -P \"modules\" -nc\n",
        "\n",
        "#dataset download if needed\n",
        "dsfiles:List[str] = [\n",
        "  \"https://drive.google.com/uc?export=download&id=1-R9ligkDV5Q0DkB3qh7VrFVqCv5SXRax\"\n",
        "]\n",
        "\n",
        "for file in dsfiles:\n",
        "  !wget --continue $file -P \"datasets\" -nc\n",
        "\n",
        "#!ls -lhia sample_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BU9a10aGHgKN"
      },
      "source": [
        "# 3. Mount google drive folder and use it if needed\n",
        "\n",
        "Mount your google drive folder with data to use in your coding\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFASyBBSHmQr"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\",force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbzammJcLdey"
      },
      "source": [
        "For instance locate your drive dataset and copy to your \"local disk\"\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11W8gFrtLh1_"
      },
      "source": [
        "\n",
        "#!gzip --keep /content/drive/MyDrive/datasets/conversion/conversion.sqlite\n",
        "#!gunzip /content/drive/MyDrive/datasets/conversion/metrics.reindexed.csv.gz\n",
        "\n",
        "!cp /content/drive/MyDrive/datasets/conversion/conversion.sqlite ./datasets/\n",
        "# Check file got downloaded\n",
        "!ls -lhia ./datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBzkeuwE5oUV"
      },
      "source": [
        "# 2. Install Conda on Google Colab\n",
        "\n",
        "<!-- By Luis Epifanio luis.epifanio@ :) -->\n",
        "\n",
        "`condacolab` simplifies the setup as much as possible, but there are some gotchas.\n",
        "\n",
        "**⚠️ Read this before continuing!**\n",
        "\n",
        "* The `condacolab` commands need to be run the first Code cell!\n",
        "* Once you run `condacolab.install()`, the Python kernel will be restarted. This is **normal and expected**. After that, you can continue running the cells below like normal.\n",
        "* Do not use the `Run all` option. Run the `condacolab` cell _individually_ and wait for the kernel to restart. **Only then**, you can run all cells if you want.\n",
        "* You can only use the `base` environment. Do not try to create new ones; instead update `base` with either:\n",
        "  * `conda install <packages>`\n",
        "  * `conda env update -n base -f environment.yml`\n",
        "* If you want to use GPUs, make sure you are using such an instance before starting!\n",
        "* If you get an error, please raise an issue [here](https://github.com/jaimergp/condacolab/issues)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAZ11nESX6qt"
      },
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "# Choose one of this, if you're in doubt choose first one\n",
        "condacolab.install()\n",
        "# condacolab.install_miniconda()\n",
        "# condacolab.install_miniforge()\n",
        "# condacolab.install_mambaforge()\n",
        "# condacolab.install_anaconda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRDyL3hPYAOx"
      },
      "source": [
        "import condacolab\n",
        "condacolab.check()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pan8GICVYOSt"
      },
      "source": [
        "Optionally, you can refresh your environment dependenedcies using next command"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVrfw3Ir0gwL"
      },
      "source": [
        "# !mamba install -q \n",
        "# TODO: Check how to update base environment from environment.yml\n",
        "# On my case located at /content/drive/MyDrive/datasets/conversion/environment.yml\n",
        "!mamba env update -n base -f environment.yml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IGeIdxpa9Gn"
      },
      "source": [
        "!conda clean -pt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uk6kZcyeL3Dk"
      },
      "source": [
        "Configure your imports to work"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o28xM6TLMGUk"
      },
      "source": [
        "# General imports\n",
        "import sqlite3\n",
        "import csv\n",
        "from sqlite3 import Error\n",
        "from typing import Dict, List, Any\n",
        "\n",
        "import pandas as pd\n",
        "from pandas import __version__ as pdversion\n",
        "print(f'{\"pandas\": <14}: {pdversion: <16}' )\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "from matplotlib import __version__ as pltversion\n",
        "print(f'{\"matplotlib\": <14}: {pltversion: <16}' )\n",
        "import seaborn as sns\n",
        "\n",
        "from fbprophet import Prophet\n",
        "from fbprophet import __version__ as fbversion\n",
        "print(f'{\"fbprophet\": <14}: {fbversion: <16}' )\n",
        "from datetime import datetime\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMsQtKVgYZ3I"
      },
      "source": [
        "from google.colab import data_table\n",
        "data_table.enable_dataframe_formatter()\n",
        "# data_table.disable_dataframe_formatter() # or disable it\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = [40, 10]\n",
        "plt.style.use(\"ggplot\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GrtbKO0MnEJ"
      },
      "source": [
        "Configure general vars \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xV3aQfQIXkdx"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZX2jrIuVD3Pt"
      },
      "source": [
        "def create_connection(db_file:str):\n",
        "    \"\"\" create a database connection to the SQLite database\n",
        "        specified by the db_file\n",
        "    :param db_file: database file\n",
        "    :return: Connection object or None\n",
        "    \"\"\"\n",
        "    conn = None\n",
        "    try:\n",
        "        conn = sqlite3.connect(db_file)\n",
        "    except Error as e:\n",
        "        print(e)\n",
        "\n",
        "    return conn\n",
        "\n",
        "\n",
        "def execute_query(conn, query:str, params:Dict = None, verbose:bool = False) -> List[Dict[str, Any]]:\n",
        "  try:\n",
        "    conn.row_factory = sqlite3.Row\n",
        "    cur = conn.cursor()\n",
        "\n",
        "    if params is not None:\n",
        "      cur.execute( query, params )\n",
        "    else :\n",
        "      cur.execute( query )\n",
        "    \n",
        "    rows = cur.fetchall()\n",
        "    result:List[Dict[str, Any]] = []\n",
        "\n",
        "    for row in rows:\n",
        "      d = dict(zip(row.keys(), row))   # a dict with column names as keys\n",
        "      result.append(d)\n",
        "\n",
        "    return result\n",
        "\n",
        "  except Error as e:\n",
        "    print(e)\n",
        "    return None\n",
        "  finally:\n",
        "    if verbose:\n",
        "      print(f\"Statement executed:\\n{query}\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0KRwTpTMdVy"
      },
      "source": [
        "# General variables\n",
        "wordkir:str = \"datasets\"\n",
        "db_location:str = f\"{wordkir}/conversion.sqlite\"\n",
        "conn = create_connection(db_location)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7KP8kljX7XB"
      },
      "source": [
        "query_tables:str = \"SELECT name FROM sqlite_master;\"\n",
        "\n",
        "query:str = \"\"\"\n",
        "SELECT\n",
        "  fecha,\n",
        "  site,\n",
        "  flow,\n",
        "  device,\n",
        "  Loading,\n",
        "  Shipping,\n",
        "  Payments,\n",
        "  Review,\n",
        "  Congrats,\n",
        "  ROUND( ( Shipping * 1.0 / Loading  ) , 2 ) as LOAD_TO_SHP,\n",
        "  ROUND( ( Payments * 1.0 / Shipping ) , 2 ) as SHP_TO_PAY,\n",
        "  ROUND( ( Review   * 1.0 / Payments ) , 2 ) as PAY_TO_REV,\n",
        "  ROUND( ( Congrats * 1.0 / Review   ) , 2 ) as REV_TO_CON,\n",
        "  ROUND( ( Congrats * 1.0 / Shipping ) , 2 ) as TOTAL,\n",
        "  CAST(strftime('%w', fecha) as integer) as day_of_week,\n",
        "  CAST(strftime('%W', fecha) as integer) as week_of_year,\n",
        "  CAST(strftime('%m', fecha) as integer) as month,\n",
        "  CAST(strftime('%Y', fecha) as integer) as year,\n",
        "  'Q' || COALESCE(NULLIF((SUBSTR(fecha, 4, 2) - 1) / 3, 0), 4) AS quarter\n",
        "FROM traffic \n",
        "WHERE \n",
        "  fecha >= '2021-01-01'\n",
        "  AND site IN ('MLM')\n",
        "  AND flow IN ('cart')\n",
        "  AND device IN ('android')\n",
        "ORDER BY \n",
        "  fecha ASC,\n",
        "  site,\n",
        "  flow,\n",
        "  device\n",
        "\"\"\"\n",
        "\n",
        "#\n",
        "# Payments,\n",
        "# Review,\n",
        "# Congrats\n",
        "#\n",
        "\n",
        "# Load the data into a DataFrame\n",
        "data = pd.read_sql_query(query, conn)\n",
        "data[\"fecha\"] = pd.to_datetime(data[\"fecha\"])\n",
        "\n",
        "data_table.DataTable(data, include_index=False, num_rows_per_page=24)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCTgPZPKYkx4"
      },
      "source": [
        "# Adjust dataframe columns if needed\n",
        "# df:pd.DataFrame = data[[\"fecha\",\"Shipping\"]]\n",
        "# df.rename(columns={\"fecha\": \"ds\", \"Shipping\": \"y\"} , inplace = True)\n",
        "# df.set_index(\"ds\", inplace=True)\n",
        "# df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeTLfdoMhIBL"
      },
      "source": [
        "query_ds:str = \"\"\"\n",
        "SELECT\n",
        "  strftime('%Y-%m-%dT%H:%M:%fZ', fecha) AS ds,\n",
        "  Shipping AS y ,\n",
        "  ROUND( ( Payments * 1.0 / Shipping ) , 2 ) as ratio\n",
        "FROM traffic \n",
        "WHERE \n",
        "  fecha >= '2020-01-01'\n",
        "  AND site IN ('MLM')\n",
        "  AND flow IN ('cart')\n",
        "  AND device IN ('android')\n",
        "ORDER BY \n",
        "  fecha ASC,\n",
        "  site,\n",
        "  flow,\n",
        "  device\n",
        "\"\"\"\n",
        "df = pd.read_sql_query(query_ds, conn)\n",
        "df[\"ds\"] = pd.to_datetime(df[\"ds\"])\n",
        "\n",
        "data_table.DataTable(df, include_index=False, num_rows_per_page=24)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggBKyhZNiIDW"
      },
      "source": [
        "df.set_index(\"ds\")[\"y\"].plot();\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwvRAoYomDD4"
      },
      "source": [
        "from modules.outlier_utils import prophet_fit, prophet_plot, get_outliers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwN7BZWCoBUp"
      },
      "source": [
        "alpha=0.98\n",
        "\n",
        "model = Prophet(\n",
        "    interval_width=alpha, \n",
        "    yearly_seasonality=False, \n",
        "    weekly_seasonality=False, \n",
        "    #holidays=us_public_holidays, \n",
        "    changepoint_prior_scale=0.5\n",
        ")\n",
        "\n",
        "model.add_seasonality(name='monthly', period=30.5, fourier_order=5)\n",
        "model.add_seasonality(name='weekly', period=7, fourier_order=3, prior_scale=0.1)\n",
        "\n",
        "today_index = 305\n",
        "print('Cutoff date: ', df.index[today_index])\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = [16, 9]\n",
        "plt.style.use(\"ggplot\")\n",
        "\n",
        "predict_n = 14\n",
        "\n",
        "fig, forecast, model = prophet_fit(df, model, today_index, predict_days=predict_n)\n",
        "\n",
        "outliers, df_pred = get_outliers(df, forecast, today_index, predict_days=predict_n)\n",
        "\n",
        "prophet_plot(df, fig, today_index, predict_days=predict_n, outliers=outliers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kInJ3FVws6E"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}